{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OchU51ENNu5d",
        "outputId": "0497a978-303c-4cee-e41b-cde985c51472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set a random seed to make random operations reproducible\n",
        "random_seed = 42  # You can choose any integer value as the seed\n",
        "\n",
        "# Set the random seed for NumPy\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "h7tcxx6iNzbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAlCxLXtN0d4",
        "outputId": "186b19df-dd51-4924-d160-09706d4e1ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import *\n",
        "from keras import initializers\n",
        "from keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "oxG0_XuSN5VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start load train set\")\n",
        "# Load and preprocess training data\n",
        "imgs_train = np.load('/content/drive/MyDrive/LUNA16/trainImages.npy').astype(np.float16)\n",
        "imgs_mask_train = np.load('/content/drive/MyDrive/LUNA16/trainMasks.npy').astype(np.float16)\n",
        "print(\"Finish load train set\")\n",
        "\n",
        "\n",
        "print(\"Start tranpose train set\")\n",
        "imgs_train = imgs_train.transpose(0, 2, 3, 1)\n",
        "imgs_mask_train = imgs_mask_train.transpose(0, 2, 3, 1)\n",
        "imgs_mask_train[imgs_mask_train > 0.] = 1.0\n",
        "print(\"Finish tranpose load train set\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jYpG_fmN53R",
        "outputId": "5b55621d-de01-4a1b-c298-c90c2ff889e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start load train set\n",
            "Finish load train set\n",
            "Start tranpose train set\n",
            "Finish tranpose load train set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_weights = {0: 0.9740012017916528, 1: 0.02599879820834716}\n",
        "print(\"Class Weights:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3LUYauSN7JZ",
        "outputId": "62436888-017d-40b9-f179-1501dffdff7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 0.9740012017916528, 1: 0.02599879820834716}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the training data into training and validation sets\n",
        "imgs_train, val_images, imgs_mask_train, val_masks = train_test_split(imgs_train, imgs_mask_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "E66scFOfN8AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(imgs, masks, batch_size=1):\n",
        "    num_samples = len(imgs)\n",
        "    if random_seed is not None:\n",
        "        np.random.seed(random_seed)  # Set the random seed\n",
        "\n",
        "    while True:\n",
        "        indices = np.random.choice(num_samples, batch_size, replace= False)\n",
        "        batch_imgs = imgs[indices]\n",
        "        batch_masks = masks[indices]\n",
        "        yield batch_imgs, batch_masks"
      ],
      "metadata": {
        "id": "6A83hOjSN96C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    smooth = 0.\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "\n",
        "    # Flatten the true and predicted masks\n",
        "    y_true_flat = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_flat = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    intersection = tf.keras.backend.sum(y_true_flat * y_pred_flat)\n",
        "    dice_coeff_class_0 = (2.0 * intersection + smooth) / (tf.keras.backend.sum(y_true_flat) + tf.keras.backend.sum(y_pred_flat) + smooth)\n",
        "\n",
        "    y_true_class_1 = 1 - y_true\n",
        "    y_pred_class_1 = 1 - y_pred\n",
        "\n",
        "    y_true_flat_class_1 = tf.keras.backend.flatten(y_true_class_1)\n",
        "    y_pred_flat_class_1 = tf.keras.backend.flatten(y_pred_class_1)\n",
        "\n",
        "    intersection_class_1 = tf.keras.backend.sum(y_true_flat_class_1 * y_pred_flat_class_1)\n",
        "    dice_coeff_class_1 = (2.0 * intersection_class_1 + smooth) / (tf.keras.backend.sum(y_true_flat_class_1) + tf.keras.backend.sum(y_pred_flat_class_1) + smooth)\n",
        "\n",
        "    # Calculate the mean of both Dice coefficients\n",
        "    dice_coefficient = (dice_coeff_class_0 + dice_coeff_class_1) / 2.0\n",
        "    return dice_coefficient\n",
        "\n",
        "def weighted_dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "bJA84pEpN_-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    weight_positive = 0.98  # Set a suitable weight for the positive class (you can experiment with different values)\n",
        "    weight_negative = 0.02  # Set a suitable weight for the negative class (you can experiment with different values)\n",
        "\n",
        "    # Calculate the binary cross-entropy loss\n",
        "    bce = K.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Apply the weights to the loss based on the true labels\n",
        "    weighted_bce = tf.where(K.equal(y_true, 1), weight_positive * bce, weight_negative * bce)\n",
        "\n",
        "    return K.mean(weighted_bce)"
      ],
      "metadata": {
        "id": "3c8J0CkSOAtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_unet_small():\n",
        "    inputs = Input((512,512,1))\n",
        "    conv1 = Conv2D(32, (3, 3), activation='elu', padding='same')(inputs)\n",
        "    conv1 = Dropout(0.2)(conv1)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='elu',padding='same', name='conv_1')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), name='pool_1')(conv1)\n",
        "    pool1 = BatchNormalization()(pool1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='elu',padding='same')(pool1)\n",
        "    conv2 = Dropout(0.2)(conv2)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='elu',padding='same', name='conv_2')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), name='pool_2')(conv2)\n",
        "    pool2 = BatchNormalization()(pool2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='elu',padding='same')(pool2)\n",
        "    conv3 = Dropout(0.2)(conv3)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='elu',padding='same', name='conv_3')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), name='pool_3')(conv3)\n",
        "    pool3 = BatchNormalization()(pool3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='elu',padding='same')(pool3)\n",
        "    conv4 = Dropout(0.2)(conv4)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='elu',padding='same', name='conv_4')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3],axis = 3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='elu',padding='same')(up7)\n",
        "    conv7 = Dropout(0.2)(conv7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='elu',padding='same', name='conv_7')(conv7)\n",
        "    conv7 = BatchNormalization()(conv7)\n",
        "\n",
        "    #up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2],axis = 3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='elu',padding='same')(up8)\n",
        "    conv8 = Dropout(0.2)(conv8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='elu',padding='same', name='conv_8')(conv8)\n",
        "    conv8 = BatchNormalization()(conv8)\n",
        "\n",
        "    #up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1],axis = 3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='elu',padding='same')(up9)\n",
        "    conv9 = Dropout(0.2)(conv9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='elu',padding='same', name='conv_9')(conv9)\n",
        "    conv9 = BatchNormalization()(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid', name='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    # Compile the model with the custom loss function and optimizer\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Cdnr0erzOB0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_subset = 100  # Choose an appropriate number of samples\n",
        "imgs_train_subset = imgs_train[:num_samples_subset]\n",
        "imgs_mask_train_subset = imgs_mask_train[:num_samples_subset]\n",
        "\n",
        "print(\"Number sample : \" ,  num_samples_subset)\n",
        "print(\"Number sample : \" ,  imgs_train_subset.shape)\n",
        "print(\"Number sample : \" ,  imgs_mask_train_subset.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBUz1P7LODIB",
        "outputId": "0d70ce51-41f5-440e-cf6a-abc98b311ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number sample :  100\n",
            "Number sample :  (100, 512, 512, 1)\n",
            "Number sample :  (100, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_subset = 50  # Choose an appropriate number of samples\n",
        "val_images= val_images[:num_samples_subset]\n",
        "val_masks = val_masks[:num_samples_subset]\n",
        "\n",
        "print(\"Number sample : \" ,  num_samples_subset)\n",
        "print(\"Number sample : \" ,  val_images.shape)\n",
        "print(\"Number sample : \" ,  val_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nw710ppObHS",
        "outputId": "5d2f9625-7055-4d80-e682-d1e6ee393b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number sample :  50\n",
            "Number sample :  (50, 512, 512, 1)\n",
            "Number sample :  (50, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train_tuning = imgs_train_subset.copy()\n",
        "print(img_train_tuning.shape)\n",
        "\n",
        "imgs_mask_train_subset_tuning = imgs_mask_train_subset.copy()\n",
        "print(imgs_mask_train_subset_tuning.shape)\n",
        "val_images_tuning = val_images.copy()\n",
        "val_masks_tuning = val_masks.copy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8zln7FfTaTu",
        "outputId": "badc979e-dbe5-4be2-d21d-94e692bc99b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 512, 512, 1)\n",
            "(100, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = get_unet_small()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skz65UQ2bCow",
        "outputId": "ea97841a-fccf-4fae-e06c-fb3d040a9be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 512, 512, 32)         320       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512, 512, 32)         0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv_1 (Conv2D)             (None, 512, 512, 32)         9248      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " pool_1 (MaxPooling2D)       (None, 256, 256, 32)         0         ['conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 256, 256, 32)         128       ['pool_1[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)         18496     ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256, 256, 64)         0         ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv_2 (Conv2D)             (None, 256, 256, 64)         36928     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " pool_2 (MaxPooling2D)       (None, 128, 128, 64)         0         ['conv_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 128, 128, 64)         256       ['pool_2[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)        73856     ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128, 128, 128)        0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv_3 (Conv2D)             (None, 128, 128, 128)        147584    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " pool_3 (MaxPooling2D)       (None, 64, 64, 128)          0         ['conv_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 64, 64, 128)          512       ['pool_3[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 256)          295168    ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64, 64, 256)          0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv_4 (Conv2D)             (None, 64, 64, 256)          590080    ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 64, 64, 256)          1024      ['conv_4[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 128, 128, 256)        0         ['batch_normalization_3[0][0]'\n",
            " D)                                                                 ]                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 128, 128, 384)        0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'conv_3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 128)        442496    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 128, 128, 128)        0         ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv_7 (Conv2D)             (None, 128, 128, 128)        147584    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 128, 128, 128)        512       ['conv_7[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 256, 256, 128)        0         ['batch_normalization_4[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'conv_2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 256, 256, 64)         110656    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 256, 256, 64)         0         ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv_8 (Conv2D)             (None, 256, 256, 64)         36928     ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 256, 256, 64)         256       ['conv_8[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 512, 512, 64)         0         ['batch_normalization_5[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 512, 512, 96)         0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 512, 512, 32)         27680     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 512, 512, 32)         0         ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv_9 (Conv2D)             (None, 512, 512, 32)         9248      ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 512, 512, 32)         128       ['conv_9[0][0]']              \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " sigmoid (Conv2D)            (None, 512, 512, 1)          33        ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1949121 (7.44 MB)\n",
            "Trainable params: 1947713 (7.43 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def create_and_train_model( steps_per_epoch, epochs, validation_data, learning_rate):\n",
        "    # Clear any previously allocated memory\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Set mixed-precision policy if supported by GPU\n",
        "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "    tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)  # Adjust the optimizer and learning rate as needed\n",
        "    model.compile(optimizer=optimizer, loss=weighted_dice_coef_loss, metrics=['accuracy', dice_coefficient])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(imgs_train_subset ,imgs_mask_train_subset, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_data)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
        "\n",
        "\n",
        "    # Create a new data generator instance for each trial\n",
        "    steps_per_epoch = len(imgs_train_subset)\n",
        "    validation_data = (val_images, val_masks)\n",
        "\n",
        "    # Create and train the model with the suggested hyperparameters\n",
        "    model = create_and_train_model(steps_per_epoch, 1, validation_data, learning_rate=learning_rate)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    metric_name = 'dice_coefficient'\n",
        "    score = model.evaluate(validation_data[0], validation_data[1], verbose=0)\n",
        "    metric_value = score[model.metrics_names.index(metric_name)]\n",
        "\n",
        "    return metric_value\n",
        "\n",
        "\n",
        "# Create a StratifiedKFold object for cross-validation (if needed)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', pruner=MedianPruner(n_warmup_steps=5))\n",
        "study.optimize(objective, n_trials = 15, timeout=5400)\n",
        "\n",
        "\n",
        "# Get the best hyperparameters and best score\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value\n",
        "print(best_params)\n",
        "print(best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxLSY-PLOkwZ",
        "outputId": "44f32b50-f69d-4a96-b74c-159e3b5558bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:09:44,215] A new study created in memory with name: no-name-927f2370-b045-4b42-8875-51ad4bf43542\n",
            "<ipython-input-16-de3eaae303e5>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 76s 531ms/step - loss: 0.9022 - accuracy: 0.5904 - dice_coefficient: 0.4146 - val_loss: 0.9389 - val_accuracy: 0.1632 - val_dice_coefficient: 0.1515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:11:04,148] Trial 0 finished with value: 0.15154191851615906 and parameters: {'learning_rate': 0.0006217288069704359}. Best is trial 0 with value: 0.15154191851615906.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 131ms/step - loss: 0.8941 - accuracy: 0.6529 - dice_coefficient: 0.4426 - val_loss: 0.9123 - val_accuracy: 0.4448 - val_dice_coefficient: 0.3437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:11:31,581] Trial 1 finished with value: 0.3436918556690216 and parameters: {'learning_rate': 0.0018546526712894685}. Best is trial 1 with value: 0.3436918556690216.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 132ms/step - loss: 0.8558 - accuracy: 0.8721 - dice_coefficient: 0.5340 - val_loss: 0.9245 - val_accuracy: 0.8113 - val_dice_coefficient: 0.4845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:11:57,828] Trial 2 finished with value: 0.48445677757263184 and parameters: {'learning_rate': 0.009207502102137704}. Best is trial 2 with value: 0.48445677757263184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 21s 131ms/step - loss: 0.7269 - accuracy: 0.9440 - dice_coefficient: 0.6218 - val_loss: 0.8842 - val_accuracy: 0.6313 - val_dice_coefficient: 0.4383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:12:24,088] Trial 3 finished with value: 0.43825411796569824 and parameters: {'learning_rate': 0.003618284952956745}. Best is trial 2 with value: 0.48445677757263184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 144ms/step - loss: 0.6389 - accuracy: 0.9547 - dice_coefficient: 0.6688 - val_loss: 0.8712 - val_accuracy: 0.6826 - val_dice_coefficient: 0.4671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:12:50,324] Trial 4 finished with value: 0.4671311378479004 and parameters: {'learning_rate': 0.0002525015764064595}. Best is trial 2 with value: 0.48445677757263184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 143ms/step - loss: 0.5904 - accuracy: 0.9593 - dice_coefficient: 0.6942 - val_loss: 0.8689 - val_accuracy: 0.9008 - val_dice_coefficient: 0.5397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:13:17,179] Trial 5 finished with value: 0.5397251844406128 and parameters: {'learning_rate': 0.0010078758035514921}. Best is trial 5 with value: 0.5397251844406128.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 131ms/step - loss: 0.5232 - accuracy: 0.9662 - dice_coefficient: 0.7297 - val_loss: 0.8179 - val_accuracy: 0.9101 - val_dice_coefficient: 0.5674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:13:43,178] Trial 6 finished with value: 0.5674395561218262 and parameters: {'learning_rate': 0.00016815389884367667}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 24s 146ms/step - loss: 0.8281 - accuracy: 0.9295 - dice_coefficient: 0.5671 - val_loss: 0.8863 - val_accuracy: 0.9277 - val_dice_coefficient: 0.5374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:14:11,055] Trial 7 finished with value: 0.5374490022659302 and parameters: {'learning_rate': 0.039298746298917164}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 24s 145ms/step - loss: 0.7605 - accuracy: 0.9312 - dice_coefficient: 0.6015 - val_loss: 0.9926 - val_accuracy: 0.9726 - val_dice_coefficient: 0.4959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:14:38,534] Trial 8 finished with value: 0.49589642882347107 and parameters: {'learning_rate': 0.012102996338067414}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 131ms/step - loss: 0.7822 - accuracy: 0.9266 - dice_coefficient: 0.5891 - val_loss: 0.9128 - val_accuracy: 0.9579 - val_dice_coefficient: 0.5340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:15:05,830] Trial 9 finished with value: 0.5339906215667725 and parameters: {'learning_rate': 0.025293175860427446}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 22s 131ms/step - loss: 0.7434 - accuracy: 0.9369 - dice_coefficient: 0.6117 - val_loss: 0.8670 - val_accuracy: 0.9019 - val_dice_coefficient: 0.5404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:15:33,194] Trial 10 finished with value: 0.540438175201416 and parameters: {'learning_rate': 0.00011244558846442039}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 23s 132ms/step - loss: 0.7363 - accuracy: 0.9377 - dice_coefficient: 0.6154 - val_loss: 0.8536 - val_accuracy: 0.8807 - val_dice_coefficient: 0.5415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:16:01,296] Trial 11 finished with value: 0.5415331125259399 and parameters: {'learning_rate': 0.0001231976980244314}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 23s 142ms/step - loss: 0.7335 - accuracy: 0.9396 - dice_coefficient: 0.6174 - val_loss: 0.8438 - val_accuracy: 0.8696 - val_dice_coefficient: 0.5427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:16:28,631] Trial 12 finished with value: 0.5427383184432983 and parameters: {'learning_rate': 0.00010015968461811918}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 23s 142ms/step - loss: 0.7267 - accuracy: 0.9408 - dice_coefficient: 0.6211 - val_loss: 0.8416 - val_accuracy: 0.8664 - val_dice_coefficient: 0.5426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:16:55,935] Trial 13 finished with value: 0.5425677299499512 and parameters: {'learning_rate': 0.0003603966186357009}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 23s 142ms/step - loss: 0.7137 - accuracy: 0.9431 - dice_coefficient: 0.6282 - val_loss: 0.8386 - val_accuracy: 0.8610 - val_dice_coefficient: 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-12 13:17:23,218] Trial 14 finished with value: 0.5421510934829712 and parameters: {'learning_rate': 0.00010429030087527029}. Best is trial 6 with value: 0.5674395561218262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.00016815389884367667}\n",
            "0.5674395561218262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def create_and_train_model( steps_per_epoch, epochs, validation_data,batch_size):\n",
        "    # Clear any previously allocated memory\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Set mixed-precision policy if supported by GPU\n",
        "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "    tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "    optimizer = Adam(learning_rate = 0.00016815389884367667)  # Adjust the optimizer and learning rate as needed\n",
        "    model.compile(optimizer=optimizer, loss=weighted_dice_coef_loss, metrics=['accuracy', dice_coefficient])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(imgs_train_subset ,imgs_mask_train_subset, batch_size = batch_size, epochs=epochs, validation_data=validation_data)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    batch_size = int(trial.suggest_loguniform('batch size', 1 , 12))\n",
        "\n",
        "\n",
        "    # Create a new data generator instance for each trial\n",
        "    steps_per_epoch = len(imgs_train_subset)\n",
        "    validation_data = (val_images, val_masks)\n",
        "\n",
        "    # Create and train the model with the suggested hyperparameters\n",
        "    model = create_and_train_model(steps_per_epoch, 1, validation_data, batch_size )\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    metric_name = 'dice_coefficient'\n",
        "    score = model.evaluate(validation_data[0], validation_data[1], verbose=0)\n",
        "    metric_value = score[model.metrics_names.index(metric_name)]\n",
        "\n",
        "    return metric_value\n",
        "\n",
        "\n",
        "# Create a StratifiedKFold object for cross-validation (if needed)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize', pruner=MedianPruner(n_warmup_steps=5))\n",
        "study.optimize(objective, n_trials = 15, timeout=5400)\n",
        "\n",
        "\n",
        "# Get the best hyperparameters and best score\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value\n",
        "print(best_params)\n",
        "print(best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d64zbRCtrR-O",
        "outputId": "b8a6a22b-3616-4710-f563-bfddd04a65ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:17:23,340] A new study created in memory with name: no-name-4aac24dc-eab1-4978-9dbb-241a235c1d0e\n",
            "<ipython-input-17-182bce2440cf>:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  batch_size = int(trial.suggest_loguniform('batch size', 1 , 12))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 44s 702ms/step - loss: 0.9102 - accuracy: 0.5682 - dice_coefficient: 0.3950 - val_loss: 0.9021 - val_accuracy: 0.6269 - val_dice_coefficient: 0.4293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:18:51,073] Trial 0 finished with value: 0.4270666241645813 and parameters: {'batch size': 5.0967228397942}. Best is trial 0 with value: 0.4270666241645813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 25s 137ms/step - loss: 0.8794 - accuracy: 0.7188 - dice_coefficient: 0.4638 - val_loss: 0.9468 - val_accuracy: 0.0286 - val_dice_coefficient: 0.0278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:19:37,740] Trial 1 finished with value: 0.028019249439239502 and parameters: {'batch size': 1.5786425118272096}. Best is trial 0 with value: 0.4270666241645813.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 40s 1s/step - loss: 0.9025 - accuracy: 0.6973 - dice_coefficient: 0.4540 - val_loss: 0.9050 - val_accuracy: 0.6429 - val_dice_coefficient: 0.4336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:20:25,615] Trial 2 finished with value: 0.43342337012290955 and parameters: {'batch size': 9.450392121978647}. Best is trial 2 with value: 0.43342337012290955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 27s 287ms/step - loss: 0.8662 - accuracy: 0.7729 - dice_coefficient: 0.4911 - val_loss: 0.8981 - val_accuracy: 0.6274 - val_dice_coefficient: 0.4314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:21:13,460] Trial 3 finished with value: 0.42867404222488403 and parameters: {'batch size': 2.114516694468992}. Best is trial 2 with value: 0.43342337012290955.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 47s 2s/step - loss: 0.8493 - accuracy: 0.8015 - dice_coefficient: 0.5092 - val_loss: 0.9227 - val_accuracy: 0.7538 - val_dice_coefficient: 0.4587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:22:41,988] Trial 4 finished with value: 0.46093758940696716 and parameters: {'batch size': 8.505333399272967}. Best is trial 4 with value: 0.46093758940696716.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 52s 2s/step - loss: 0.8376 - accuracy: 0.8198 - dice_coefficient: 0.5220 - val_loss: 0.9000 - val_accuracy: 0.6479 - val_dice_coefficient: 0.4361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:24:09,427] Trial 5 finished with value: 0.4353561997413635 and parameters: {'batch size': 11.412483094091836}. Best is trial 4 with value: 0.46093758940696716.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 20s 514ms/step - loss: 0.8345 - accuracy: 0.8251 - dice_coefficient: 0.5235 - val_loss: 0.9112 - val_accuracy: 0.7095 - val_dice_coefficient: 0.4549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:24:35,477] Trial 6 finished with value: 0.4524589776992798 and parameters: {'batch size': 4.396197954057843}. Best is trial 4 with value: 0.46093758940696716.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 30s 802ms/step - loss: 0.8244 - accuracy: 0.8359 - dice_coefficient: 0.5320 - val_loss: 0.9143 - val_accuracy: 0.7245 - val_dice_coefficient: 0.4556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:25:07,659] Trial 7 finished with value: 0.456312894821167 and parameters: {'batch size': 6.73734558456346}. Best is trial 4 with value: 0.46093758940696716.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 20s 258ms/step - loss: 0.8145 - accuracy: 0.8589 - dice_coefficient: 0.5424 - val_loss: 0.8967 - val_accuracy: 0.6905 - val_dice_coefficient: 0.4557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:25:31,459] Trial 8 finished with value: 0.4514511227607727 and parameters: {'batch size': 2.6436737835282065}. Best is trial 4 with value: 0.46093758940696716.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 21s 834ms/step - loss: 0.7936 - accuracy: 0.8736 - dice_coefficient: 0.5576 - val_loss: 0.8952 - val_accuracy: 0.8296 - val_dice_coefficient: 0.4994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:25:58,845] Trial 9 finished with value: 0.49649208784103394 and parameters: {'batch size': 6.750032254968859}. Best is trial 9 with value: 0.49649208784103394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 29s 399ms/step - loss: 0.7851 - accuracy: 0.8824 - dice_coefficient: 0.5641 - val_loss: 0.9195 - val_accuracy: 0.8073 - val_dice_coefficient: 0.4821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:26:47,092] Trial 10 finished with value: 0.4782499670982361 and parameters: {'batch size': 3.4922954919073197}. Best is trial 9 with value: 0.49649208784103394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 23s 423ms/step - loss: 0.7748 - accuracy: 0.8912 - dice_coefficient: 0.5721 - val_loss: 0.8425 - val_accuracy: 0.9279 - val_dice_coefficient: 0.5570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:27:13,272] Trial 11 finished with value: 0.5515937805175781 and parameters: {'batch size': 3.625248670507454}. Best is trial 11 with value: 0.5515937805175781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 22s 691ms/step - loss: 0.7609 - accuracy: 0.8975 - dice_coefficient: 0.5812 - val_loss: 0.8708 - val_accuracy: 0.9429 - val_dice_coefficient: 0.5476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:27:37,827] Trial 12 finished with value: 0.5400627851486206 and parameters: {'batch size': 5.187976099328234}. Best is trial 11 with value: 0.5515937805175781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 20s 133ms/step - loss: 0.7587 - accuracy: 0.9017 - dice_coefficient: 0.5848 - val_loss: 0.8828 - val_accuracy: 0.6085 - val_dice_coefficient: 0.4274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:28:02,372] Trial 13 finished with value: 0.42336928844451904 and parameters: {'batch size': 1.0433025016102957}. Best is trial 11 with value: 0.5515937805175781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 20s 383ms/step - loss: 0.7227 - accuracy: 0.9205 - dice_coefficient: 0.6082 - val_loss: 0.7537 - val_accuracy: 0.8877 - val_dice_coefficient: 0.5834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-13 13:28:29,537] Trial 14 finished with value: 0.5820558071136475 and parameters: {'batch size': 3.89779746018928}. Best is trial 14 with value: 0.5820558071136475.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch size': 3.89779746018928}\n",
            "0.5820558071136475\n"
          ]
        }
      ]
    }
  ]
}