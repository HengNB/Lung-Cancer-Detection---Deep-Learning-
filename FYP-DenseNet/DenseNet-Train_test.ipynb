{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEg4feLtpIaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5308927e-d694-4707-ce82-a9c5d1fd1ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz2tNLVxq8aR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Add , MaxPooling2D,GlobalAveragePooling2D, Dense , Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import *\n",
        "from keras import initializers\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouaL0ycnq6ER"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Start load train set\")\n",
        "# Load and preprocess training data\n",
        "imgs_train = np.load('/content/drive/MyDrive/LUNA16/trainImages.npy').astype(np.float16)\n",
        "imgs_mask_train = np.load('/content/drive/MyDrive/LUNA16/trainMasks.npy').astype(np.float16)\n",
        "print(\"Finish load train set\")\n",
        "\n",
        "print(\"Start tranpose train set\")\n",
        "imgs_train = imgs_train.transpose(0, 2, 3, 1)\n",
        "imgs_mask_train = imgs_mask_train.transpose(0, 2, 3, 1)\n",
        "imgs_mask_train[imgs_mask_train > 0.] = 1.0\n",
        "print(\"Finish tranpose load train set\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktAKDUGaq-hC"
      },
      "outputs": [],
      "source": [
        "print(\"Train img shape : \",imgs_train.shape)\n",
        "print(\"Train mask shape : \",imgs_mask_train.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qICW-q-rFYR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the training data into training and validation sets\n",
        "imgs_train, val_images, imgs_mask_train, val_masks = train_test_split(imgs_train, imgs_mask_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train img shape:\", imgs_train.shape)\n",
        "print(\"Train mask shape:\", imgs_mask_train.shape)\n",
        "print(\"Validation img shape:\", val_images.shape)\n",
        "print(\"Validation mask shape:\", val_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCdTY7ldaFPH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# num_positive_pixels_train = np.sum(imgs_mask_train == 1)\n",
        "# num_negative_pixels_train = np.sum(imgs_mask_train == 0)\n",
        "# print(\"Num positive pixel\" ,num_positive_pixels_train)\n",
        "# print(\"Num negative pixel\" ,num_negative_pixels_train)\n",
        "\n",
        "# total_samples = num_negative_pixels_train + num_positive_pixels_train\n",
        "# print(\"total / num \")\n",
        "# print(\"0 : \" , total_samples/num_negative_pixels_train)\n",
        "# print(\"1 : \" , total_samples / num_positive_pixels_train)\n",
        "\n",
        "# print(\"num / total \")\n",
        "# print(\"0 : \" , num_negative_pixels_train/total_samples)\n",
        "# print(\"1 : \" , num_positive_pixels_train/total_samples)\n",
        "\n",
        "\n",
        "# class_weights = np.array([ 0.9740243197407962 , 0.02597568025920382 ])\n",
        "# class_weights =  np.array([0.02597568, 0.97402432])\n",
        "# total_samples = 14109012 + 529053356\n",
        "# num_classes = 2\n",
        "# class_samples_positive = 14109012\n",
        "# class_samples_negative = 529053356\n",
        "\n",
        "# class_weight_positive = total_samples / (num_classes * class_samples_positive)\n",
        "# class_weight_negative = total_samples / (num_classes * class_samples_negative)\n",
        "\n",
        "# print(\"Class Weight for Positive Class 0 :\", class_weight_positive)\n",
        "# print(\"Class Weight for Negative Class 1 :\", class_weight_negative)\n",
        "\n",
        "# class_weights = np.array([ class_weight_negative , class_weight_positive ])\n",
        "\n",
        "# Try this\n",
        "\n",
        "class_weights =  np.array([0.02, 1.2])\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d84nhgaS_B1b"
      },
      "outputs": [],
      "source": [
        "def data_generator(imgs, masks, batch_size=1):\n",
        "    num_samples = len(imgs)\n",
        "    while True:\n",
        "        indices = np.random.choice(num_samples, batch_size, replace=False)\n",
        "        batch_imgs = imgs[indices]\n",
        "        batch_masks = masks[indices]\n",
        "        yield batch_imgs, batch_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7BzAlAi_Zua"
      },
      "outputs": [],
      "source": [
        "# Renormalizing the masks\n",
        "imgs_mask_train[imgs_mask_train > 0.] = 1.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq07Q4w1W9Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce693c51-2743-4fcb-e8e4-fe312d41ee01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 512, 512, 16)      144       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512, 512, 16)     64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512, 512, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512, 512, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512, 512, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512, 512, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 512, 512, 16)      128       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512, 512, 16)     64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 512, 512, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 512, 512, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 512, 512, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 512, 512, 8)      32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 512, 512, 20)      160       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 512, 512, 20)     80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 512, 512, 20)      0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 512, 512, 32)      640       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 512, 512, 26)      208       \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 512, 512, 26)     104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 512, 512, 26)      0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 512, 512, 1)       27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,355\n",
            "Trainable params: 25,479\n",
            "Non-trainable params: 876\n",
            "_________________________________________________________________\n",
            "(1, 512, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Dense, AveragePooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "def Bottleneck(x, growth_rate):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(4 * growth_rate, kernel_size=1, padding='same', use_bias=False)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(growth_rate, kernel_size=3, padding='same', use_bias=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def Transition(x, out_planes):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(out_planes, kernel_size=1, padding='same', use_bias=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def DenseNet(blocks, growth_rate=12, reduction=0.5, num_classes=1):\n",
        "    num_planes = 2 * growth_rate\n",
        "    input_tensor = Input(shape=(512, 512, 1))\n",
        "    x = Conv2D(num_planes, kernel_size=3, padding='same', use_bias=False)(input_tensor)\n",
        "\n",
        "    dense_blocks = []\n",
        "    for nblock in blocks:\n",
        "        for _ in range(nblock):\n",
        "            x = Bottleneck(x, growth_rate)\n",
        "            dense_blocks.append(x)\n",
        "            num_planes += growth_rate\n",
        "\n",
        "        if reduction is not None:\n",
        "            num_planes = int(num_planes * reduction)\n",
        "            x = Transition(x, num_planes)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Adjusted the final Conv2D layer to output 1 channel\n",
        "    x = Conv2D(num_classes, kernel_size=1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def densenet_custom():\n",
        "    return DenseNet([2, 3, 4], growth_rate=8)\n",
        "\n",
        "# Test the model\n",
        "def test_densenet():\n",
        "    net = densenet_custom()\n",
        "    x = tf.random.normal((1, 512, 512, 1))\n",
        "    y = net(x)\n",
        "    print(y.shape)\n",
        "\n",
        "# Call the test function\n",
        "test_densenet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx6zbMfyI56d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1. - dice_coef(y_true, y_pred)\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "\n",
        "    # Flatten the true and predicted masks\n",
        "    y_true_flat = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_flat = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    intersection = tf.keras.backend.sum(y_true_flat * y_pred_flat)\n",
        "    dice_coeff_class_0 = (2.0 * intersection + smooth) / (tf.keras.backend.sum(y_true_flat) + tf.keras.backend.sum(y_pred_flat) + smooth)\n",
        "\n",
        "    y_true_class_1 = 1 - y_true\n",
        "    y_pred_class_1 = 1 - y_pred\n",
        "\n",
        "    y_true_flat_class_1 = tf.keras.backend.flatten(y_true_class_1)\n",
        "    y_pred_flat_class_1 = tf.keras.backend.flatten(y_pred_class_1)\n",
        "\n",
        "    intersection_class_1 = tf.keras.backend.sum(y_true_flat_class_1 * y_pred_flat_class_1)\n",
        "    dice_coeff_class_1 = (2.0 * intersection_class_1 + smooth) / (tf.keras.backend.sum(y_true_flat_class_1) + tf.keras.backend.sum(y_pred_flat_class_1) + smooth)\n",
        "\n",
        "    # Calculate the mean of both Dice coefficients\n",
        "    dice_coefficient = (dice_coeff_class_0 + dice_coeff_class_1) / 2.0\n",
        "    return dice_coefficient\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred)\n",
        "    return (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "# def weighted_dice_coef_loss(y_true, y_pred):\n",
        "#     return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def weighted_dice_coef_loss(class_weights):\n",
        "    def loss(y_true, y_pred):\n",
        "        # Calculate the Dice coefficient\n",
        "        dice_coeff = dice_coef(y_true, y_pred)\n",
        "\n",
        "        # Apply class weights to the Dice coefficient\n",
        "        weighted_dice_loss = (1.0 - dice_coeff) * class_weights\n",
        "\n",
        "        return weighted_dice_loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah5DMK3nIj9F",
        "outputId": "f956d66d-959a-4201-afd3-3a5d0b2c9a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train img shape :  (2072, 512, 512, 1)\n",
            "Train mask shape :  (2072, 512, 512, 1)\n",
            "Creating and compiling model...\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 512, 512, 16)      144       \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 512, 512, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 512, 512, 16)      128       \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 512, 512, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 512, 512, 20)      160       \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 512, 512, 20)     80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 512, 512, 20)      0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 512, 512, 32)      640       \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 512, 512, 26)      208       \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 512, 512, 26)     104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 512, 512, 26)      0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 512, 512, 1)       27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,355\n",
            "Trainable params: 25,479\n",
            "Non-trainable params: 876\n",
            "_________________________________________________________________\n",
            "Generate data...... \n",
            "Train img shape :  (2072, 512, 512, 1)\n",
            "Train mask shape :  (2072, 512, 512, 1)\n",
            "Fitting model...\n",
            "Epoch 1/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.7593 - dice_coefficient: 0.4715\n",
            "Epoch 1: val_dice_coefficient improved from -inf to 0.49496, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 198s 1s/step - loss: 0.5503 - accuracy: 0.7593 - dice_coefficient: 0.4715 - val_loss: 0.6074 - val_accuracy: 0.9739 - val_dice_coefficient: 0.4950\n",
            "Epoch 2/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.9262 - dice_coefficient: 0.5588\n",
            "Epoch 2: val_dice_coefficient did not improve from 0.49496\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.5145 - accuracy: 0.9262 - dice_coefficient: 0.5588 - val_loss: 0.6094 - val_accuracy: 0.9739 - val_dice_coefficient: 0.4937\n",
            "Epoch 3/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.9330 - dice_coefficient: 0.5715\n",
            "Epoch 3: val_dice_coefficient improved from 0.49496 to 0.52843, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.5014 - accuracy: 0.9330 - dice_coefficient: 0.5715 - val_loss: 0.5657 - val_accuracy: 0.9680 - val_dice_coefficient: 0.5284\n",
            "Epoch 4/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.9387 - dice_coefficient: 0.5819\n",
            "Epoch 4: val_dice_coefficient improved from 0.52843 to 0.57810, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4906 - accuracy: 0.9387 - dice_coefficient: 0.5819 - val_loss: 0.4951 - val_accuracy: 0.9375 - val_dice_coefficient: 0.5781\n",
            "Epoch 5/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 0.9408 - dice_coefficient: 0.5834\n",
            "Epoch 5: val_dice_coefficient improved from 0.57810 to 0.58438, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4895 - accuracy: 0.9408 - dice_coefficient: 0.5834 - val_loss: 0.4942 - val_accuracy: 0.9591 - val_dice_coefficient: 0.5844\n",
            "Epoch 6/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.9469 - dice_coefficient: 0.5912\n",
            "Epoch 6: val_dice_coefficient improved from 0.58438 to 0.59403, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4819 - accuracy: 0.9469 - dice_coefficient: 0.5912 - val_loss: 0.4818 - val_accuracy: 0.9582 - val_dice_coefficient: 0.5940\n",
            "Epoch 7/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.9495 - dice_coefficient: 0.5976\n",
            "Epoch 7: val_dice_coefficient improved from 0.59403 to 0.60278, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4750 - accuracy: 0.9495 - dice_coefficient: 0.5976 - val_loss: 0.4700 - val_accuracy: 0.9529 - val_dice_coefficient: 0.6028\n",
            "Epoch 8/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.9505 - dice_coefficient: 0.6025\n",
            "Epoch 8: val_dice_coefficient improved from 0.60278 to 0.60502, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4693 - accuracy: 0.9505 - dice_coefficient: 0.6025 - val_loss: 0.4688 - val_accuracy: 0.9570 - val_dice_coefficient: 0.6050\n",
            "Epoch 9/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.9527 - dice_coefficient: 0.6074\n",
            "Epoch 9: val_dice_coefficient did not improve from 0.60502\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4641 - accuracy: 0.9527 - dice_coefficient: 0.6074 - val_loss: 0.4696 - val_accuracy: 0.9405 - val_dice_coefficient: 0.5999\n",
            "Epoch 10/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.9538 - dice_coefficient: 0.6111\n",
            "Epoch 10: val_dice_coefficient did not improve from 0.60502\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4599 - accuracy: 0.9538 - dice_coefficient: 0.6111 - val_loss: 0.4676 - val_accuracy: 0.9334 - val_dice_coefficient: 0.5995\n",
            "Epoch 11/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.9545 - dice_coefficient: 0.6154\n",
            "Epoch 11: val_dice_coefficient improved from 0.60502 to 0.60861, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4549 - accuracy: 0.9545 - dice_coefficient: 0.6154 - val_loss: 0.4604 - val_accuracy: 0.9449 - val_dice_coefficient: 0.6086\n",
            "Epoch 12/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.9561 - dice_coefficient: 0.6171\n",
            "Epoch 12: val_dice_coefficient improved from 0.60861 to 0.61258, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4534 - accuracy: 0.9561 - dice_coefficient: 0.6171 - val_loss: 0.4597 - val_accuracy: 0.9569 - val_dice_coefficient: 0.6126\n",
            "Epoch 13/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.9560 - dice_coefficient: 0.6179\n",
            "Epoch 13: val_dice_coefficient did not improve from 0.61258\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4523 - accuracy: 0.9560 - dice_coefficient: 0.6179 - val_loss: 0.4661 - val_accuracy: 0.9394 - val_dice_coefficient: 0.6022\n",
            "Epoch 14/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.9568 - dice_coefficient: 0.6204\n",
            "Epoch 14: val_dice_coefficient improved from 0.61258 to 0.62090, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4495 - accuracy: 0.9568 - dice_coefficient: 0.6204 - val_loss: 0.4504 - val_accuracy: 0.9618 - val_dice_coefficient: 0.6209\n",
            "Epoch 15/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.9567 - dice_coefficient: 0.6215\n",
            "Epoch 15: val_dice_coefficient did not improve from 0.62090\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4482 - accuracy: 0.9567 - dice_coefficient: 0.6215 - val_loss: 0.4544 - val_accuracy: 0.9545 - val_dice_coefficient: 0.6160\n",
            "Epoch 16/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.9568 - dice_coefficient: 0.6235\n",
            "Epoch 16: val_dice_coefficient did not improve from 0.62090\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4457 - accuracy: 0.9568 - dice_coefficient: 0.6235 - val_loss: 0.4580 - val_accuracy: 0.9408 - val_dice_coefficient: 0.6094\n",
            "Epoch 17/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.9572 - dice_coefficient: 0.6255\n",
            "Epoch 17: val_dice_coefficient improved from 0.62090 to 0.62365, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4434 - accuracy: 0.9572 - dice_coefficient: 0.6255 - val_loss: 0.4467 - val_accuracy: 0.9613 - val_dice_coefficient: 0.6236\n",
            "Epoch 18/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.9573 - dice_coefficient: 0.6266\n",
            "Epoch 18: val_dice_coefficient did not improve from 0.62365\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4421 - accuracy: 0.9573 - dice_coefficient: 0.6266 - val_loss: 0.4574 - val_accuracy: 0.9411 - val_dice_coefficient: 0.6099\n",
            "Epoch 19/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.9584 - dice_coefficient: 0.6286\n",
            "Epoch 19: val_dice_coefficient improved from 0.62365 to 0.63082, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4400 - accuracy: 0.9584 - dice_coefficient: 0.6286 - val_loss: 0.4379 - val_accuracy: 0.9600 - val_dice_coefficient: 0.6308\n",
            "Epoch 20/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.9585 - dice_coefficient: 0.6294\n",
            "Epoch 20: val_dice_coefficient did not improve from 0.63082\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4391 - accuracy: 0.9585 - dice_coefficient: 0.6294 - val_loss: 0.4494 - val_accuracy: 0.9531 - val_dice_coefficient: 0.6195\n",
            "Epoch 21/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.9587 - dice_coefficient: 0.6327\n",
            "Epoch 21: val_dice_coefficient did not improve from 0.63082\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4351 - accuracy: 0.9587 - dice_coefficient: 0.6327 - val_loss: 0.4465 - val_accuracy: 0.9532 - val_dice_coefficient: 0.6217\n",
            "Epoch 22/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.9595 - dice_coefficient: 0.6352\n",
            "Epoch 22: val_dice_coefficient did not improve from 0.63082\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4323 - accuracy: 0.9595 - dice_coefficient: 0.6352 - val_loss: 0.4465 - val_accuracy: 0.9485 - val_dice_coefficient: 0.6205\n",
            "Epoch 23/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.9599 - dice_coefficient: 0.6373\n",
            "Epoch 23: val_dice_coefficient did not improve from 0.63082\n",
            "172/172 [==============================] - 178s 1s/step - loss: 0.4300 - accuracy: 0.9599 - dice_coefficient: 0.6373 - val_loss: 0.4587 - val_accuracy: 0.9653 - val_dice_coefficient: 0.6153\n",
            "Epoch 24/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.9609 - dice_coefficient: 0.6389\n",
            "Epoch 24: val_dice_coefficient improved from 0.63082 to 0.63325, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4282 - accuracy: 0.9609 - dice_coefficient: 0.6389 - val_loss: 0.4373 - val_accuracy: 0.9675 - val_dice_coefficient: 0.6332\n",
            "Epoch 25/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.9604 - dice_coefficient: 0.6384\n",
            "Epoch 25: val_dice_coefficient did not improve from 0.63325\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4287 - accuracy: 0.9604 - dice_coefficient: 0.6384 - val_loss: 0.5006 - val_accuracy: 0.9729 - val_dice_coefficient: 0.5827\n",
            "Epoch 26/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.9611 - dice_coefficient: 0.6413\n",
            "Epoch 26: val_dice_coefficient did not improve from 0.63325\n",
            "172/172 [==============================] - 178s 1s/step - loss: 0.4254 - accuracy: 0.9611 - dice_coefficient: 0.6413 - val_loss: 0.4372 - val_accuracy: 0.9477 - val_dice_coefficient: 0.6279\n",
            "Epoch 27/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.9616 - dice_coefficient: 0.6441\n",
            "Epoch 27: val_dice_coefficient did not improve from 0.63325\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4221 - accuracy: 0.9616 - dice_coefficient: 0.6441 - val_loss: 0.4374 - val_accuracy: 0.9633 - val_dice_coefficient: 0.6318\n",
            "Epoch 28/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.9604 - dice_coefficient: 0.6387\n",
            "Epoch 28: val_dice_coefficient did not improve from 0.63325\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4283 - accuracy: 0.9604 - dice_coefficient: 0.6387 - val_loss: 0.4659 - val_accuracy: 0.9675 - val_dice_coefficient: 0.6099\n",
            "Epoch 29/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.9617 - dice_coefficient: 0.6450\n",
            "Epoch 29: val_dice_coefficient did not improve from 0.63325\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4210 - accuracy: 0.9617 - dice_coefficient: 0.6450 - val_loss: 0.4331 - val_accuracy: 0.9484 - val_dice_coefficient: 0.6314\n",
            "Epoch 30/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.9615 - dice_coefficient: 0.6447\n",
            "Epoch 30: val_dice_coefficient improved from 0.63325 to 0.64150, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4214 - accuracy: 0.9615 - dice_coefficient: 0.6447 - val_loss: 0.4235 - val_accuracy: 0.9574 - val_dice_coefficient: 0.6415\n",
            "Epoch 31/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.9618 - dice_coefficient: 0.6469\n",
            "Epoch 31: val_dice_coefficient did not improve from 0.64150\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4188 - accuracy: 0.9618 - dice_coefficient: 0.6469 - val_loss: 0.4292 - val_accuracy: 0.9674 - val_dice_coefficient: 0.6393\n",
            "Epoch 32/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.9623 - dice_coefficient: 0.6493\n",
            "Epoch 32: val_dice_coefficient improved from 0.64150 to 0.64470, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4161 - accuracy: 0.9623 - dice_coefficient: 0.6493 - val_loss: 0.4190 - val_accuracy: 0.9561 - val_dice_coefficient: 0.6447\n",
            "Epoch 33/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.9630 - dice_coefficient: 0.6533\n",
            "Epoch 33: val_dice_coefficient improved from 0.64470 to 0.64562, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4114 - accuracy: 0.9630 - dice_coefficient: 0.6533 - val_loss: 0.4218 - val_accuracy: 0.9684 - val_dice_coefficient: 0.6456\n",
            "Epoch 34/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.9636 - dice_coefficient: 0.6545\n",
            "Epoch 34: val_dice_coefficient did not improve from 0.64562\n",
            "172/172 [==============================] - 178s 1s/step - loss: 0.4101 - accuracy: 0.9636 - dice_coefficient: 0.6545 - val_loss: 0.4236 - val_accuracy: 0.9548 - val_dice_coefficient: 0.6406\n",
            "Epoch 35/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.9633 - dice_coefficient: 0.6533\n",
            "Epoch 35: val_dice_coefficient improved from 0.64562 to 0.65039, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4114 - accuracy: 0.9633 - dice_coefficient: 0.6533 - val_loss: 0.4144 - val_accuracy: 0.9640 - val_dice_coefficient: 0.6504\n",
            "Epoch 36/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.9634 - dice_coefficient: 0.6557\n",
            "Epoch 36: val_dice_coefficient did not improve from 0.65039\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4085 - accuracy: 0.9634 - dice_coefficient: 0.6557 - val_loss: 0.4209 - val_accuracy: 0.9645 - val_dice_coefficient: 0.6458\n",
            "Epoch 37/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.9637 - dice_coefficient: 0.6558\n",
            "Epoch 37: val_dice_coefficient did not improve from 0.65039\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4085 - accuracy: 0.9637 - dice_coefficient: 0.6558 - val_loss: 0.4212 - val_accuracy: 0.9566 - val_dice_coefficient: 0.6434\n",
            "Epoch 38/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.9633 - dice_coefficient: 0.6547\n",
            "Epoch 38: val_dice_coefficient did not improve from 0.65039\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4097 - accuracy: 0.9633 - dice_coefficient: 0.6547 - val_loss: 0.4138 - val_accuracy: 0.9613 - val_dice_coefficient: 0.6504\n",
            "Epoch 39/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.9646 - dice_coefficient: 0.6581\n",
            "Epoch 39: val_dice_coefficient improved from 0.65039 to 0.65323, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4060 - accuracy: 0.9646 - dice_coefficient: 0.6581 - val_loss: 0.4112 - val_accuracy: 0.9643 - val_dice_coefficient: 0.6532\n",
            "Epoch 40/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.9644 - dice_coefficient: 0.6590\n",
            "Epoch 40: val_dice_coefficient did not improve from 0.65323\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4049 - accuracy: 0.9644 - dice_coefficient: 0.6590 - val_loss: 0.4155 - val_accuracy: 0.9680 - val_dice_coefficient: 0.6506\n",
            "Epoch 41/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.9645 - dice_coefficient: 0.6593\n",
            "Epoch 41: val_dice_coefficient improved from 0.65323 to 0.65680, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4045 - accuracy: 0.9645 - dice_coefficient: 0.6593 - val_loss: 0.4083 - val_accuracy: 0.9680 - val_dice_coefficient: 0.6568\n",
            "Epoch 42/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.9653 - dice_coefficient: 0.6635\n",
            "Epoch 42: val_dice_coefficient did not improve from 0.65680\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3996 - accuracy: 0.9653 - dice_coefficient: 0.6635 - val_loss: 0.4485 - val_accuracy: 0.9658 - val_dice_coefficient: 0.6234\n",
            "Epoch 43/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.9648 - dice_coefficient: 0.6596\n",
            "Epoch 43: val_dice_coefficient did not improve from 0.65680\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4043 - accuracy: 0.9648 - dice_coefficient: 0.6596 - val_loss: 0.4160 - val_accuracy: 0.9544 - val_dice_coefficient: 0.6466\n",
            "Epoch 44/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.9652 - dice_coefficient: 0.6649\n",
            "Epoch 44: val_dice_coefficient did not improve from 0.65680\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3979 - accuracy: 0.9652 - dice_coefficient: 0.6649 - val_loss: 0.4127 - val_accuracy: 0.9580 - val_dice_coefficient: 0.6506\n",
            "Epoch 45/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.9652 - dice_coefficient: 0.6626\n",
            "Epoch 45: val_dice_coefficient improved from 0.65680 to 0.66051, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4007 - accuracy: 0.9652 - dice_coefficient: 0.6626 - val_loss: 0.4036 - val_accuracy: 0.9693 - val_dice_coefficient: 0.6605\n",
            "Epoch 46/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.9657 - dice_coefficient: 0.6652\n",
            "Epoch 46: val_dice_coefficient did not improve from 0.66051\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3976 - accuracy: 0.9657 - dice_coefficient: 0.6652 - val_loss: 0.4132 - val_accuracy: 0.9555 - val_dice_coefficient: 0.6493\n",
            "Epoch 47/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.9651 - dice_coefficient: 0.6629\n",
            "Epoch 47: val_dice_coefficient did not improve from 0.66051\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.4003 - accuracy: 0.9651 - dice_coefficient: 0.6629 - val_loss: 0.4055 - val_accuracy: 0.9599 - val_dice_coefficient: 0.6568\n",
            "Epoch 48/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.9645 - dice_coefficient: 0.6628\n",
            "Epoch 48: val_dice_coefficient improved from 0.66051 to 0.66051, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.4003 - accuracy: 0.9645 - dice_coefficient: 0.6628 - val_loss: 0.4037 - val_accuracy: 0.9683 - val_dice_coefficient: 0.6605\n",
            "Epoch 49/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.9659 - dice_coefficient: 0.6674\n",
            "Epoch 49: val_dice_coefficient did not improve from 0.66051\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3952 - accuracy: 0.9659 - dice_coefficient: 0.6674 - val_loss: 0.4055 - val_accuracy: 0.9670 - val_dice_coefficient: 0.6584\n",
            "Epoch 50/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.9656 - dice_coefficient: 0.6646\n",
            "Epoch 50: val_dice_coefficient did not improve from 0.66051\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3984 - accuracy: 0.9656 - dice_coefficient: 0.6646 - val_loss: 0.4135 - val_accuracy: 0.9578 - val_dice_coefficient: 0.6495\n",
            "Epoch 51/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.9654 - dice_coefficient: 0.6662\n",
            "Epoch 51: val_dice_coefficient did not improve from 0.66051\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3965 - accuracy: 0.9654 - dice_coefficient: 0.6662 - val_loss: 0.4089 - val_accuracy: 0.9541 - val_dice_coefficient: 0.6525\n",
            "Epoch 52/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.9662 - dice_coefficient: 0.6695\n",
            "Epoch 52: val_dice_coefficient improved from 0.66051 to 0.66703, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3926 - accuracy: 0.9662 - dice_coefficient: 0.6695 - val_loss: 0.3939 - val_accuracy: 0.9645 - val_dice_coefficient: 0.6670\n",
            "Epoch 53/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.9657 - dice_coefficient: 0.6658\n",
            "Epoch 53: val_dice_coefficient did not improve from 0.66703\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3970 - accuracy: 0.9657 - dice_coefficient: 0.6658 - val_loss: 0.4157 - val_accuracy: 0.9584 - val_dice_coefficient: 0.6478\n",
            "Epoch 54/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.9652 - dice_coefficient: 0.6637\n",
            "Epoch 54: val_dice_coefficient did not improve from 0.66703\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3994 - accuracy: 0.9652 - dice_coefficient: 0.6637 - val_loss: 0.3961 - val_accuracy: 0.9638 - val_dice_coefficient: 0.6653\n",
            "Epoch 55/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.9669 - dice_coefficient: 0.6708\n",
            "Epoch 55: val_dice_coefficient did not improve from 0.66703\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3913 - accuracy: 0.9669 - dice_coefficient: 0.6708 - val_loss: 0.4054 - val_accuracy: 0.9604 - val_dice_coefficient: 0.6569\n",
            "Epoch 56/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.9668 - dice_coefficient: 0.6694\n",
            "Epoch 56: val_dice_coefficient did not improve from 0.66703\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3929 - accuracy: 0.9668 - dice_coefficient: 0.6694 - val_loss: 0.4141 - val_accuracy: 0.9578 - val_dice_coefficient: 0.6487\n",
            "Epoch 57/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.9667 - dice_coefficient: 0.6701\n",
            "Epoch 57: val_dice_coefficient improved from 0.66703 to 0.66748, saving model to /content/drive/MyDrive/LUNA16/DensenetModel.hdf5\n",
            "172/172 [==============================] - 180s 1s/step - loss: 0.3920 - accuracy: 0.9667 - dice_coefficient: 0.6701 - val_loss: 0.3953 - val_accuracy: 0.9706 - val_dice_coefficient: 0.6675\n",
            "Epoch 58/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.9667 - dice_coefficient: 0.6713\n",
            "Epoch 58: val_dice_coefficient did not improve from 0.66748\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3906 - accuracy: 0.9667 - dice_coefficient: 0.6713 - val_loss: 0.4139 - val_accuracy: 0.9537 - val_dice_coefficient: 0.6481\n",
            "Epoch 59/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.9669 - dice_coefficient: 0.6710\n",
            "Epoch 59: val_dice_coefficient did not improve from 0.66748\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3911 - accuracy: 0.9669 - dice_coefficient: 0.6710 - val_loss: 0.3975 - val_accuracy: 0.9614 - val_dice_coefficient: 0.6633\n",
            "Epoch 60/60\n",
            "173/172 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.9666 - dice_coefficient: 0.6697\n",
            "Epoch 60: val_dice_coefficient did not improve from 0.66748\n",
            "172/172 [==============================] - 179s 1s/step - loss: 0.3924 - accuracy: 0.9666 - dice_coefficient: 0.6697 - val_loss: 0.4319 - val_accuracy: 0.9366 - val_dice_coefficient: 0.6290\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x792308978850>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "epochs = 60\n",
        "\n",
        "print(\"Train img shape : \",imgs_train.shape)\n",
        "print(\"Train mask shape : \",imgs_mask_train.shape)\n",
        "\n",
        "\n",
        "print('Creating and compiling model...')\n",
        "model = densenet_custom()\n",
        "model.compile(optimizer= Adam(learning_rate=0.005), loss=weighted_dice_coef_loss(class_weights), metrics=['accuracy',dice_coefficient])\n",
        "# model.compile(optimizer='adam', loss=weighted_dice_coef_loss, metrics=['accuracy', dice_coefficient])\n",
        "\n",
        "# Define model checkpoints\n",
        "filepath = \"/content/drive/MyDrive/LUNA16/DensenetModel.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_dice_coefficient', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
        "\n",
        "print('Generate data...... ')\n",
        "\n",
        "# Use generator for training data to reduce memory usage\n",
        "train_generator = data_generator(imgs_train, imgs_mask_train, batch_size=12)\n",
        "steps_per_epoch = len(imgs_train) / 12\n",
        "validation_data = (val_images, val_masks)\n",
        "\n",
        "# Set mixed-precision policy if supported by GPU\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "\n",
        "print(\"Train img shape : \",imgs_train.shape)\n",
        "print(\"Train mask shape : \",imgs_mask_train.shape)\n",
        "\n",
        "print('Fitting model...')\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs = epochs, validation_data=validation_data, callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0eB70XQOPwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66130a69-8f9c-4fba-c1c1-9004bf323ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start load test set\n",
            "Finish load test set\n",
            "Start tranpose load test set\n",
            "Finish tranpose load test set\n"
          ]
        }
      ],
      "source": [
        "print(\"Start load test set\")\n",
        "# Load and preprocess test data\n",
        "imgs_test = np.load('/content/drive/MyDrive/LUNA16/testImages.npy').astype(np.float16)\n",
        "imgs_mask_test_true = np.load('/content/drive/MyDrive/LUNA16/testMasks.npy').astype(np.float16)\n",
        "print(\"Finish load test set\")\n",
        "\n",
        "\n",
        "print(\"Start tranpose load test set\")\n",
        "imgs_test = imgs_test.transpose(0, 2, 3, 1)\n",
        "imgs_mask_test_true = imgs_mask_test_true.transpose(0, 2, 3, 1)\n",
        "imgs_mask_test_true[imgs_mask_test_true > 0] = 1.0\n",
        "print(\"Finish tranpose load test set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6HXJotFOTKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef24af90-8ecb-4912-bd42-651d33f58413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 512, 512, 16)      144       \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 512, 512, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 512, 512, 16)      128       \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 512, 512, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 512, 512, 16)      0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 512, 512, 32)      512       \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 512, 512, 20)      160       \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 512, 512, 20)     80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 512, 512, 20)      0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 512, 512, 32)      640       \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 512, 512, 32)      256       \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 512, 512, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 512, 512, 8)       2304      \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 512, 512, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 512, 512, 8)       0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 512, 512, 26)      208       \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 512, 512, 26)     104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 512, 512, 26)      0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 512, 512, 1)       27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,355\n",
            "Trainable params: 25,479\n",
            "Non-trainable params: 876\n",
            "_________________________________________________________________\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the model architecture and create the model object (if needed)\n",
        "# Assuming you have defined the model architecture somewhere\n",
        "model = densenet_custom()\n",
        "model.compile(optimizer= Adam(learning_rate=0.005), loss=weighted_dice_coef_loss(class_weights), metrics=['accuracy',dice_coefficient])\n",
        "\n",
        "# Specify the path to the HDF5 file containing the saved model weights\n",
        "weights_path = \"/content/drive/MyDrive/LUNA16/DensenetModel.hdf5\"\n",
        "\n",
        "# Load the model weights from the HDF5 file\n",
        "model.load_weights(weights_path)\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.measure import label, regionprops\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Specify the Malaysia time zone\n",
        "malaysia_time_zone = pytz.timezone('Asia/Kuala_Lumpur')\n",
        "\n",
        "y_pred = model.predict(imgs_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(np.float16)\n",
        "\n",
        "print(\"Y_pred_binary : \", y_pred_binary.shape)\n",
        "# Define your min and max size thresholds\n",
        "min_size = 600\n",
        "max_size = 10201\n",
        "\n",
        "# Initialize an array for filtered binary predictions\n",
        "filtered_pred_binary = np.zeros_like(y_pred_binary)\n",
        "\n",
        "for i in range(len(y_pred_binary)):\n",
        "    labeled_regions = label(y_pred_binary[i])\n",
        "\n",
        "    region_props = regionprops(labeled_regions)\n",
        "    for region in region_props:\n",
        "        region_area = region.area\n",
        "        if min_size <= region_area <= max_size:\n",
        "            filtered_pred_binary[i][labeled_regions == region.label] = 1\n",
        "print(\"filtered_pred_binary : \", filtered_pred_binary.shape)\n",
        "print(\"Generating report ... \")\n",
        "\n",
        "\n",
        "start_time = datetime.now(malaysia_time_zone)\n",
        "start_formatted_time = start_time.strftime(\"%I:%M %p\")\n",
        "print(\"Start time : \", start_formatted_time)\n",
        "# Evaluate the filtered predictions using appropriate metrics\n",
        "filtered_classification_rep = classification_report(imgs_mask_test_true.flatten(), filtered_pred_binary.flatten())\n",
        "end_time = datetime.now(malaysia_time_zone)\n",
        "end_formatted_time = end_time.strftime(\"%I:%M %p\")\n",
        "print(\"End time : \" , end_formatted_time)\n",
        "# Print the metrics for filtered predictions\n",
        "print(\"Filtered Classification Report:\")\n",
        "print(filtered_classification_rep)"
      ],
      "metadata": {
        "id": "-Cs_7fLlhtZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae0a3c8-0b77-462f-c589-0ff156ce8c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 16s 561ms/step\n",
            "Y_pred_binary :  (647, 512, 512, 1)\n",
            "filtered_pred_binary :  (647, 512, 512, 1)\n",
            "Generating report ... \n",
            "Start time :  03:52 PM\n",
            "End time :  04:28 PM\n",
            "Filtered Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99 165203890\n",
            "         1.0       0.64      0.25      0.36   4403278\n",
            "\n",
            "    accuracy                           0.98 169607168\n",
            "   macro avg       0.81      0.62      0.67 169607168\n",
            "weighted avg       0.97      0.98      0.97 169607168\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "accuracy = accuracy_score(imgs_mask_test_true.flatten(), filtered_pred_binary.flatten())\n",
        "accuracy_percentage = accuracy * 100  # Convert accuracy to percentage\n",
        "\n",
        "# Format and print the accuracy as a percentage with two decimal places\n",
        "formatted_accuracy = \"{:.2f}\".format(accuracy_percentage)\n",
        "print(\"Accuracy:\", formatted_accuracy, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5WDZpNQWxQm",
        "outputId": "3e170141-ec34-476a-b286-8eee119d7e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.68 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Calculate the confusion matrix\n",
        "# confusion = confusion_matrix(imgs_mask_test_true.flatten(), filtered_pred_binary.flatten())\n",
        "\n",
        "# Plot the confusion matrix as a heatmap with a red color scheme\n",
        "# Plot the confusion matrix as a heatmap with the RdBu colormap\n",
        "# Define custom colors for annotations\n",
        "colors = [ \"skyblue\", \"blue\"]\n",
        "cmap = sns.color_palette(colors)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap with custom colors\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False,\n",
        "            xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "b2Eihkt2Wy7O",
        "outputId": "68b64de4-1728-43df-be0f-eed919f47000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}